# Doc-AI-Enhanced-Autism-Spectrum-Disorder-Therapy-Session-Analysis-with-Computer-Vision-

Hello! Welcome to "Doc-AI: Enhanced Autism Spectrum Disorder Therapy Session Analysis with Computer Vision."
Title : Integrated IoT-based hardware-software codesign approach/machinery for the detection of Autism spectrum disorder and interpretation.

Abstract: Autism Spectrum Disorder is a neuro-developmental condition, involving patients where the main issues would be in social interaction problems and communication problems with repetitive behaviors. The symptoms and severity of individuals vary. Since most of the classical techniques were too time-consuming and read by hand, thus lacking proper detection of an ASD, this device is an effort to overcome such problems. The innovation here discusses a method to do that. This patent will describe an advanced computer vision pipeline meant for the assessment and evaluation of therapist-child interactions in ASD therapy. Therefore, the system uses real-time object tracking to detect complex models such as DETR, Face Emotion Detection FER, Gaze Transformer, and extended video observation like DeepFace. Additionally, the IOT parts we are using include EEG, which provides physiological data to render an understanding of the extent of emotion as well as the extent of mental involvement. This invention, therefore, can produce detailed reports suitable for the needs of the patient based on the data that might be gathered through this pipelined complex process.
It significantly reduces the time and effort for a manual analysis, so this improves the whole process of assessment, bringing more efficient and individualized therapy to children diagnosed as suffering from ASD.

Whereas till date I have uploaded all the files related to software model alone.

Objectives :

The aim of this project is to design and construct an advanced system for analyzing the interaction between therapists and children during therapy sessions.
It will include integrations with IoT devices for the monitoring of real-time object interactions through pipelining of EEG and computer vision.
The system recognises emotions, predicts eye-gaze patterns, and tracks levels of engagement by the child.
This project will give an all-round and proper understanding by computerizing an evaluation of videos of extended therapy sessions and including physiological information from EEG sensors. It expands the treatment interventions and also improves ASD's accuracy and efficiency. 
Integrated IoT-Based Hardware-Software Codesign: A System Architecture
![image](https://github.com/user-attachments/assets/b9531277-c873-40ba-ad9c-b7c9879883bf)
Working Cycle for Software Model : Video (input) -> Convert it into single frames -> extract frame -> first Process it with Object detection -> find physical engagement through movements -> find human-object interaction -> generate captions -> Annotate frames -> Generate video with annotations -> generate a detailed report

Computer vision models used :

Computer Vision Models:
Detection Transformer (DETR)
Face Emotion Detection (FER)
DeepFace
Gaze Transformer

